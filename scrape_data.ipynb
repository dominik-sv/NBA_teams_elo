{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1263ae8b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2faa7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac108fb0",
   "metadata": {},
   "source": [
    "# Format url (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af159a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schedule_url(year: str, league: str, m_link: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Create a basketball-reference URL for the basketball schedule page.\n",
    "\n",
    "    Parameters:\n",
    "    year (str): The season year.\n",
    "    league (str): The basketball league.\n",
    "    m_link (str, optional): The full ending link, specific for a month.\n",
    "\n",
    "    Returns:\n",
    "    (str): A basketball-reference URL pointing to the desired basketball schedule page.\n",
    "    \"\"\"\n",
    "    if m_link == None:\n",
    "        url = f\"https://www.basketball-reference.com/leagues/{league}_{year}_games.html\"\n",
    "    else:\n",
    "        url = f\"https://www.basketball-reference.com{m_link}\"\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17bf9b",
   "metadata": {},
   "source": [
    "# Request HTML (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7583f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_request_times = deque()\n",
    "\n",
    "def get_request_soup(url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Sends a GET request to a URL and returns a BeautifulSoup object. Handles not sending too many\n",
    "    requests to not get a rate limited request (429) from basketball-reference.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): A URL pointing to the desired page.\n",
    "\n",
    "    Returns:\n",
    "    BeautifulSoup: Parsed HTML content of the requested page.\n",
    "\n",
    "    Exceptions:\n",
    "    Terminates the entire python script if the response status code is 429.\n",
    "    Raises an HTTP error if response status code is problematic.\n",
    "    Prints an error message if the request fails due to connection, timeout, or other issues.\n",
    "    \"\"\"\n",
    "    ## !!! Bot Limit: 20 reqeusts per min !!!\n",
    "    global _request_times\n",
    "\n",
    "    # Delete timestamps older than a minute\n",
    "    a_minute_ago = time.monotonic() - 60\n",
    "    while _request_times and _request_times[0] < a_minute_ago:\n",
    "        _request_times.popleft()\n",
    "\n",
    "    # Check if less than 15 requests have been made in the last minute\n",
    "    if len(_request_times) >= 15:\n",
    "        oldest_request = _request_times[0]\n",
    "        sleep_time = oldest_request - a_minute_ago\n",
    "        if sleep_time > 0:\n",
    "            print(f\"Too many requests. Pausing for: {sleep_time:.2f}\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    # Request HTML\n",
    "    try:\n",
    "        wait_time = random.uniform(3, 5)\n",
    "        time.sleep(wait_time)\n",
    "        response = requests.get(url)\n",
    "        _request_times.append(time.monotonic())\n",
    "\n",
    "        # Check response\n",
    "        if response.status_code == 429:\n",
    "            print(\"Too many requests (response code 429) - You are in jail for an hour :(\")\n",
    "            print(\"Saving collected data into dataframe named df\")\n",
    "            sys.exit()\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return soup\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Failed to connect to basketball-reference site\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"The request timed out\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984eb07",
   "metadata": {},
   "source": [
    "# Get starting dates of playoffs (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97848ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_dates_of_playoffs() -> dict:\n",
    "    \"\"\"\n",
    "    Returns the starting date of the playoffs for every year for each of the major american\n",
    "    basketball leagues (NBA, ABA, BAA) using basketball-reference's playoff series list.\n",
    "    Is also used to infer which seasons should be scraped.\n",
    "\n",
    "    Returns:\n",
    "    dict: A nested dictionary where:\n",
    "        key (str): The league shortcut.\n",
    "        nested key (str): The season year.\n",
    "        value (datetime): The date of the beggining of the playoffs.\n",
    "\n",
    "    Notes:\n",
    "    It relies on an external helper function `get_request_soup(url)` to receive the parsed HTML content.\n",
    "    \"\"\"\n",
    "    starting_dates = {\"NBA\": {}, \"ABA\": {}, \"BAA\": {}}\n",
    "\n",
    "    playoffs_url = \"https://www.basketball-reference.com/playoffs/series.html\"\n",
    "    soup = get_request_soup(playoffs_url)\n",
    "    playoffs_series_table = soup.find(\"table\", id=\"playoffs_series\")\n",
    "    tbody = playoffs_series_table.find(\"tbody\")\n",
    "\n",
    "    for trow in tbody.find_all(\"tr\"):\n",
    "\n",
    "        if trow.has_attr(\"csk\"):\n",
    "            continue  # Not yet finished playoff series\n",
    "\n",
    "        if \"class\" in trow.attrs and any(\n",
    "            class_name in (\"thead\", \"overheader\")\n",
    "            for class_name in trow.get(\"class\", [])\n",
    "        ):\n",
    "            continue  # Header of table\n",
    "\n",
    "        year = trow.find(\"th\", {\"data-stat\": \"season\"}).text.strip()\n",
    "        league = trow.find(\"td\", {\"data-stat\": \"lg\"}).text.strip()\n",
    "        month_day = trow.find(\"td\", {\"data-stat\": \"date_range\"}).text.strip()[:6]\n",
    "        full_date = f\"{month_day} {year}\"\n",
    "        s_date = datetime.strptime(full_date, \"%b %d %Y\")\n",
    "\n",
    "        if year not in starting_dates[league]:\n",
    "            starting_dates[league][year] = []\n",
    "        starting_dates[league][year].append(s_date)\n",
    "\n",
    "    playoffs_starting_dates = {\"NBA\": {}, \"ABA\": {}, \"BAA\": {}}\n",
    "    for league in starting_dates:\n",
    "        for year in starting_dates[league]:\n",
    "            playoffs_starting_dates[league][year] = min(starting_dates[league][year])\n",
    "\n",
    "    return playoffs_starting_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6c442",
   "metadata": {},
   "source": [
    "# Get match data for a season (multiple functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e7f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_of_games_in_season(soup: Tag) -> list:\n",
    "    \"\"\"\n",
    "    Extracts list of endings of urls for sites for each month during which basketball\n",
    "    games where played for given year and league.\n",
    "\n",
    "    Parameters:\n",
    "    soup (bs4.BeautifulSoup): A parsed BeautifulSoup object containing the HTML of the basketball schedule page.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of ending parts of urls.\n",
    "    \"\"\"\n",
    "    month_links = []\n",
    "    filter_div = soup.find(\"div\", class_=\"filter\")\n",
    "    \n",
    "    for div in filter_div.find_all(\"div\"):\n",
    "        m_link = div.find(\"a\")[\"href\"]\n",
    "        month_links.append(m_link)\n",
    "    return month_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12926bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_point(key: str, text: str) -> datetime | int | str:\n",
    "    \"\"\"\n",
    "    Parses match data point based on its key.\n",
    "\n",
    "    Parameters:\n",
    "    key (str): Name of the data point.\n",
    "    text (str): Text content of the data point\n",
    "\n",
    "    Returns:\n",
    "    (datetime): If the key is 'date'.\n",
    "    (int): If the key is 'visitor_pts', 'home_pts' or 'overtime' (representing number of overtimes played).\n",
    "    (string): For all other keys.\n",
    "    \"\"\"\n",
    "    if key == \"date\":\n",
    "        try:\n",
    "            return datetime.strptime(text, \"%a, %b %d, %Y\")\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert {key} with value: ({text}) to datetime.\")\n",
    "            return datetime(2000, 1, 1)\n",
    "\n",
    "    elif key in (\"visitor_pts\", \"home_pts\"):\n",
    "        try:\n",
    "            return int(text)\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert {key} with value: {text} to integer.\")\n",
    "            return 0\n",
    "\n",
    "    elif key == \"overtime\":\n",
    "        if text == \"\":\n",
    "            return 0\n",
    "        elif text == \"OT\":\n",
    "            return 1\n",
    "        else:\n",
    "            try:\n",
    "                return int(text[:-2])\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert {key} with value: {text} to integer by omitting the last two characters.\")\n",
    "                return 0\n",
    "\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948a75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(trow: Tag) -> dict | None:\n",
    "    \"\"\"\n",
    "    Extracts basketball match data from a <tr> HTML element.\n",
    "\n",
    "    Parameters:\n",
    "    trow (bs4.element.Tag): A BeautifulSoup <tr> tag representing one row with data points about a single basketball match.\n",
    "\n",
    "    Returns:\n",
    "    dict | None:\n",
    "        dict: A dictionary with the following keys:\n",
    "            - 'date' (datetime): The date of the game.\n",
    "            - 'visitor_name' (str): Name of the visiting team.\n",
    "            - 'visitor_pts' (int): Points scored by the visiting team.\n",
    "            - 'home_name' (str): Name of the home team.\n",
    "            - 'home_pts' (int): Points scored by the home team.\n",
    "            - 'overtime' (int): Number of overtime periods.\n",
    "        None: If the trow is missing data or match hasn't been played yet.\n",
    "\n",
    "    Notes:\n",
    "    It relies on an external helper function `parse_data_point(key, text)` to handle value conversion.\n",
    "    \"\"\"\n",
    "    match_data = {}\n",
    "    data_fields = {\n",
    "        \"date\": (\"th\", \"date_game\"),\n",
    "        \"visitor_name\": (\"td\", \"visitor_team_name\"),\n",
    "        \"visitor_pts\": (\"td\", \"visitor_pts\"),\n",
    "        \"home_name\": (\"td\", \"home_team_name\"),\n",
    "        \"home_pts\": (\"td\", \"home_pts\"),\n",
    "        \"overtime\": (\"td\", \"overtimes\"),\n",
    "    }\n",
    "\n",
    "    # Scrape needed data points\n",
    "    for key, (tag, data_stat) in data_fields.items():\n",
    "        try:\n",
    "            text = trow.find(tag, {\"data-stat\": data_stat}).text.strip()\n",
    "        except AttributeError:\n",
    "            print(f\"Attribute error for {key} in this trow: \\n\", trow)\n",
    "            return None\n",
    "\n",
    "        data_point = parse_data_point(key, text)\n",
    "        match_data[key] = data_point\n",
    "\n",
    "        if key == \"date\" and data_point.date() >= datetime.now().date():\n",
    "            return None  # Skips matches that haven't been played yet\n",
    "\n",
    "    # Calculate values needed for elo\n",
    "    match_data[\"home_win\"] = (\n",
    "        True if match_data[\"home_pts\"] > match_data[\"visitor_pts\"] else False\n",
    "    )\n",
    "    match_data[\"margin_of_victory\"] = abs(\n",
    "        match_data[\"home_pts\"] - match_data[\"visitor_pts\"]\n",
    "    )\n",
    "\n",
    "    return match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc31e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data_for_season(year: str, league: str, playoff_starting_date: datetime) -> list:\n",
    "    \"\"\"\n",
    "    Scrapes all relevant match data for an entire basketball season from basketball-reference.\n",
    "\n",
    "    Parameters:\n",
    "    year (str): The season year.\n",
    "    playoff_starting_date (datetime): The starting date of the playoffs that year for given league.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of matches (for an entire season) with game data.\n",
    "    \"\"\"\n",
    "    all_matches = []\n",
    "\n",
    "    # Find months when games are played\n",
    "    default_url = create_schedule_url(year, league)\n",
    "    soup = get_request_soup(default_url)\n",
    "    month_links = get_months_of_games_in_season(soup)\n",
    "\n",
    "    # Get game data\n",
    "    for m_link in month_links:\n",
    "        month_url = create_schedule_url(year, league, m_link=m_link)\n",
    "        soup_month = get_request_soup(month_url)\n",
    "\n",
    "        table = soup_month.find(\"table\", id=\"schedule\")\n",
    "        tbody = table.find(\"tbody\")\n",
    "        for trow in tbody.find_all(\"tr\"):\n",
    "            if \"thead\" in trow.get(\"class\", []):\n",
    "                continue  # Header of table\n",
    "\n",
    "            match_data = get_match_data(trow)\n",
    "            if match_data is None:\n",
    "                continue  # Faulty match or match that hasn't been played yet\n",
    "            \n",
    "            match_data[\"postseason\"] = True if playoff_starting_date <= match_data[\"date\"] else False\n",
    "            match_data[\"season\"] = year\n",
    "            match_data[\"league\"] = league\n",
    "            all_matches.append(match_data)\n",
    "\n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c0f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_of_batches(window_size: int, num_of_years_to_process: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the number of batches the scraping will be split into. Splitting into batches and\n",
    "    exporting data by batches helps save scraping progress when network or other errors might arise.\n",
    "\n",
    "    Parameters:\n",
    "    window_size (int): Number of years each batch should contain.\n",
    "    years_to_process (int): Number of years needed to process.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of batches the scraping will be split into.\n",
    "    \"\"\"\n",
    "    return num_of_years_to_process // window_size + (\n",
    "        num_of_years_to_process % window_size > 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42519499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(\n",
    "    batch_year_league: list, batch: int, num_of_batches: int, playoffs_starting_dates: dict\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Processing one batch of seasons (different years or different leagues). Includes progress bar.\n",
    "\n",
    "    Parameters:\n",
    "    batch_year_league (list): List of tuples containing (season year, league name).\n",
    "    batch (int): Batch number.\n",
    "    num_of_batches (int): Total number of batches.\n",
    "    playoffs_starting_dates (dict): A nested dictionary with league names (str) as keys containing\n",
    "    key, value pairs of season year (str) and starting date of playoffs (datetime).\n",
    "\n",
    "    Returns:\n",
    "    list: Match data for all matches in given season for a given league.\n",
    "\n",
    "    Note:\n",
    "    Relies on function `get_match_data_for_season` that collects all match data for a given season.\n",
    "    \"\"\"\n",
    "    all_batch_matches = []\n",
    "\n",
    "    for year, league in tqdm(\n",
    "        batch_year_league, desc=f\"Processing batch {batch+1}/{num_of_batches}\"\n",
    "    ):\n",
    "        season_matches = get_match_data_for_season(\n",
    "            year, league, playoffs_starting_dates[league][year]\n",
    "        )\n",
    "        all_batch_matches.extend(season_matches)\n",
    "\n",
    "    return all_batch_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee23b93",
   "metadata": {},
   "source": [
    "# Run entire code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0728a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBA': {'2025': datetime.datetime(2025, 4, 19, 0, 0), '2024': datetime.datetime(2024, 4, 20, 0, 0), '2023': datetime.datetime(2023, 4, 15, 0, 0), '2022': datetime.datetime(2022, 4, 16, 0, 0), '2021': datetime.datetime(2021, 5, 22, 0, 0), '2020': datetime.datetime(2020, 8, 17, 0, 0), '2019': datetime.datetime(2019, 4, 13, 0, 0), '2018': datetime.datetime(2018, 4, 14, 0, 0), '2017': datetime.datetime(2017, 4, 15, 0, 0), '2016': datetime.datetime(2016, 4, 16, 0, 0), '2015': datetime.datetime(2015, 4, 18, 0, 0), '2014': datetime.datetime(2014, 4, 19, 0, 0), '2013': datetime.datetime(2013, 4, 20, 0, 0), '2012': datetime.datetime(2012, 4, 28, 0, 0), '2011': datetime.datetime(2011, 4, 16, 0, 0), '2010': datetime.datetime(2010, 4, 17, 0, 0), '2009': datetime.datetime(2009, 4, 18, 0, 0), '2008': datetime.datetime(2008, 4, 19, 0, 0), '2007': datetime.datetime(2007, 4, 21, 0, 0), '2006': datetime.datetime(2006, 4, 22, 0, 0), '2005': datetime.datetime(2005, 4, 23, 0, 0), '2004': datetime.datetime(2004, 4, 17, 0, 0), '2003': datetime.datetime(2003, 4, 19, 0, 0), '2002': datetime.datetime(2002, 4, 20, 0, 0), '2001': datetime.datetime(2001, 4, 21, 0, 0), '2000': datetime.datetime(2000, 4, 22, 0, 0), '1999': datetime.datetime(1999, 5, 8, 0, 0), '1998': datetime.datetime(1998, 4, 23, 0, 0), '1997': datetime.datetime(1997, 4, 24, 0, 0), '1996': datetime.datetime(1996, 4, 25, 0, 0), '1995': datetime.datetime(1995, 4, 27, 0, 0), '1994': datetime.datetime(1994, 4, 28, 0, 0), '1993': datetime.datetime(1993, 4, 29, 0, 0), '1992': datetime.datetime(1992, 4, 23, 0, 0), '1991': datetime.datetime(1991, 4, 25, 0, 0), '1990': datetime.datetime(1990, 4, 26, 0, 0), '1989': datetime.datetime(1989, 4, 27, 0, 0), '1988': datetime.datetime(1988, 4, 28, 0, 0), '1987': datetime.datetime(1987, 4, 23, 0, 0), '1986': datetime.datetime(1986, 4, 17, 0, 0), '1985': datetime.datetime(1985, 4, 17, 0, 0), '1984': datetime.datetime(1984, 4, 17, 0, 0), '1983': datetime.datetime(1983, 4, 19, 0, 0), '1982': datetime.datetime(1982, 4, 20, 0, 0), '1981': datetime.datetime(1981, 3, 31, 0, 0), '1980': datetime.datetime(1980, 4, 2, 0, 0), '1979': datetime.datetime(1979, 4, 10, 0, 0), '1978': datetime.datetime(1978, 4, 11, 0, 0), '1977': datetime.datetime(1977, 4, 12, 0, 0), '1976': datetime.datetime(1976, 4, 13, 0, 0), '1975': datetime.datetime(1975, 4, 8, 0, 0), '1974': datetime.datetime(1974, 3, 29, 0, 0), '1973': datetime.datetime(1973, 3, 30, 0, 0), '1972': datetime.datetime(1972, 3, 28, 0, 0), '1971': datetime.datetime(1971, 3, 24, 0, 0), '1970': datetime.datetime(1970, 3, 25, 0, 0), '1969': datetime.datetime(1969, 3, 26, 0, 0), '1968': datetime.datetime(1968, 3, 22, 0, 0), '1967': datetime.datetime(1967, 3, 21, 0, 0), '1966': datetime.datetime(1966, 3, 23, 0, 0), '1965': datetime.datetime(1965, 3, 24, 0, 0), '1964': datetime.datetime(1964, 3, 21, 0, 0), '1963': datetime.datetime(1963, 3, 19, 0, 0), '1962': datetime.datetime(1962, 3, 16, 0, 0), '1961': datetime.datetime(1961, 3, 14, 0, 0), '1960': datetime.datetime(1960, 3, 11, 0, 0), '1959': datetime.datetime(1959, 3, 13, 0, 0), '1958': datetime.datetime(1958, 3, 15, 0, 0), '1957': datetime.datetime(1957, 3, 14, 0, 0), '1956': datetime.datetime(1956, 3, 15, 0, 0), '1955': datetime.datetime(1955, 3, 15, 0, 0), '1954': datetime.datetime(1954, 3, 24, 0, 0), '1953': datetime.datetime(1953, 3, 17, 0, 0), '1952': datetime.datetime(1952, 3, 18, 0, 0), '1951': datetime.datetime(1951, 3, 20, 0, 0), '1950': datetime.datetime(1950, 3, 20, 0, 0)}, 'ABA': {'1976': datetime.datetime(1976, 4, 8, 0, 0), '1975': datetime.datetime(1975, 4, 4, 0, 0), '1974': datetime.datetime(1974, 3, 29, 0, 0), '1973': datetime.datetime(1973, 3, 30, 0, 0), '1972': datetime.datetime(1972, 3, 31, 0, 0), '1971': datetime.datetime(1971, 4, 1, 0, 0), '1970': datetime.datetime(1970, 4, 17, 0, 0), '1969': datetime.datetime(1969, 4, 5, 0, 0), '1968': datetime.datetime(1968, 3, 23, 0, 0)}, 'BAA': {'1949': datetime.datetime(1949, 3, 22, 0, 0), '1948': datetime.datetime(1948, 3, 23, 0, 0), '1947': datetime.datetime(1947, 4, 2, 0, 0)}}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\NBA_teams_elo\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Get a dictionary of starting dates of playoffs for every year for every league\n",
    "playoffs_starting_dates = get_starting_dates_of_playoffs()\n",
    "\n",
    "# Get years to process\n",
    "years_to_process = []\n",
    "for league in [\"NBA\", \"ABA\", \"BAA\"]:\n",
    "    for year in playoffs_starting_dates[league].keys():\n",
    "        years_to_process.append((year, league))\n",
    "\n",
    "# Prepare batch number and batch sizes\n",
    "WINDOW_SIZE = 7\n",
    "num_of_batches = calculate_number_of_batches(WINDOW_SIZE, len(years_to_process))\n",
    "\n",
    "# Directory\n",
    "directory = \"Data\"\n",
    "directory2 = \"partial_match_data\"\n",
    "combined_directory = os.path.join(directory, directory2)\n",
    "os.makedirs(combined_directory, exist_ok=True)\n",
    "\n",
    "# Scrape data by batches\n",
    "for batch in range(0, num_of_batches):\n",
    "    batch_year_league = years_to_process[batch * WINDOW_SIZE : (batch + 1) * WINDOW_SIZE]\n",
    "    all_batch_matches = process_batch(batch_year_league, batch, num_of_batches, playoffs_starting_dates)\n",
    "    \n",
    "    # Convert to df and export\n",
    "    df = pd.DataFrame(all_batch_matches)\n",
    "    filepath = os.path.join(combined_directory, f\"match_data_{batch}.csv\")\n",
    "    df.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
